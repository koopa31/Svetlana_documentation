Usage
=====

Note that Svetlana works with all kinds of image types (2D, 3D, multichannel).
A Youtube tutorial video is available here.

.. _data_organization:
Organizing the data
------------
First of all, you need your image(s) to be segmented in a certain way. Each ROI
of the segmentation mask must be given a unique integer value (label),
so each ROI can then be classified. To segment cells, you can refer to Cellpose for instance.

Once you segmented your data, it must be organized in a specific way:
::

    parent folder
    ├── Images
    │   ├── image1
    │   ...
    │   └── imageN
    ├── Masks
    │  ├── mask1
    │   ...
    │  └── maskN

The parent folder name doesn't matter, nevertheless the subfolder Images and Masks must
**absolutely** be called this way.


.. _annotation:

Annotation
------------

The labelling
~~~~~~~~~~~~~~~~~~~
Now the dataset is well organized, we can start annotating.

First, data must be loaded, loading the parent folder. Then, a patch size around the ROI must be chosen
(the bigger the more contextual information). This patch size can be either automatically estimated, based on the biggest ROI in the mask,
or set by the user.

Finally, there are two ways to label, whatever the type of image (2D, 3D etc).

#. Letting Svetlana propose patches one after another in a random order (default way).
#. Clicking on the objects, then clicking the label number. Can be useful in case the dataset is unbalanced in terms of cells number of each class in the image. For that, activate the option ticking the corresponding case.

Saving the result
~~~~~~~~~~~~~~~~~~~
Once the user is satisfied by the number of ROI he made, he can click on
**save the result** button to create a binary file stored in a folder called
Svetlana.

This binary file called labels is then going to be used by the training plugin.


Resuming labeling
~~~~~~~~~~~~~~~~~~~
For some reasons (resume training to perform transfer learning for instance), you may want
to resume labeling. For that, a dedicated button is available and must be used instead of the load data button.
It works the same, i.e. the parent folder must be chosen.

If a training has already been performed, it will also load the previous predictions, so the user
can see where the NN made mistakes. Moreover, if a "confidence" mask containing the NN probability for each ROI
has been generated by the user (optional) during the prediction, an coloured overlay is also going to be generated.
It is a rainbow mask varying from blue (low confidence) to red (high confidence).

.. _training:
Training
----------------

Data loading
~~~~~~~~~~~~~~~~~~~
A load data button is dedicated to loading the labels binary file generated in the Svetlana folder.
It contains all the useful information to perform the training.

Choosing the NN
~~~~~~~~~~~~~~~~~~~
First choose 2D or 3D to get the list of appropriate NN architectures as a function of
the type of image you are going to process.
Then a lot of architectures are available (see paper for more details).

The optimization parameters
~~~~~~~~~~~~~~~~~~~
The main parameters are present in the GUI. But if you want to setup more precisely
the parameters, a JSON configuration file is present in Svetlana folder (created in the parent folder).
You can change the decay parameters of the learning rate as well as the weights decay of ADAM optimizer.

The data augmentation
~~~~~~~~~~~~~~~~~~~
A very basic data augmentation is available, but using the configuration file,it is possible to perform all the complex data augmentations proposed in the Albumentations
library. To do so, please refer to the `documentation <https://albumentations.ai/docs/getting_started/transforms_and_targets/>`_,
and add all the needed parameters to the JSON configuration file.

**Example:**

Gaussian blurring in documentation :

.. code-block:: python

    GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=False, p=0.5)


Equivalent in JSON configuration file:

.. code-block:: json

    "GaussianBlur": {
          "apply": "False",
          "blur_limit": "(3, 7)",
          "sigma_limit": "0",
          "p": "0.5"
      }


where _apply_ means you want this data augmentation to be applied or not.

The patch multiplied by a dilated mask (optional)
~~~~~~~~~~~~~~~~~~~
As shown in the paper, it is possible to reduce the contextual information around the object in the patch.
To do so, we dilate the segmentation mask of the patch and multiply the image by it (see paper for more details).
This can be set in the configuration file setting the apply option to True. Moreover, the user can choose the size of the structural element for the dilation in voxels.

.. figure:: docs/images/patch.png
    :width: 30 %

    Without multiplying by dilated mask
.. figure:: docs/images/dilated_patch.png
    :width: 30 %

    Multiplying by dilated mask

The transfer learning
~~~~~~~~~~~~~~~~~~~

If you don't want to train a NN from scratch, you can use the resume labeling button,
and choose the NN weights file you want to start from. This enable to recursively improve your NN performance,
just like in Cellpose for instance.

.. _prediction:
Prediction
----------------

NN loading
~~~~~~~~~~~~~~~~~~~
Load network button asks the user to choose the weights file of the training the user wants to use.

Data loading
~~~~~~~~~~~~~~~~~~~
Choose the parent folder.

Choice of the batch size
~~~~~~~~~~~~~~~~~~~
This variable defines how many patches are going to be processed at the same time (parallelization),
in order to earn time. Obviously, the more RAM your GPU has, the greater this parameter can be chosen.

Prediction of an image
~~~~~~~~~~~~~~~~~~~

You can choose to predict only the image you are visualizing. Therefore, the prediction mask is going to be displayed.
You can tick a case to also predict the confidence mask explained above.

Prediction of a batch of images
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You can choose to predict the whole folder. Therefore, no result is going to be displayed, but all the results will be stored
in a folder called **Predictions**.
You can also tick a case to predict the confidence mask explained above.